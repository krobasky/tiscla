
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>Welcome to sbr’s documentation! &#8212; sbr v0.1 documentation</title>
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="_static/language_data.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="module-sbr.compile">
<span id="welcome-to-sbr-s-documentation"></span><h1>Welcome to sbr’s documentation!<a class="headerlink" href="#module-sbr.compile" title="Permalink to this headline">¶</a></h1>
<dl class="function">
<dt id="sbr.compile.one_layer_multicategorical">
<code class="descclassname">sbr.compile.</code><code class="descname">one_layer_multicategorical</code><span class="sig-paren">(</span><em>input_size=None</em>, <em>output_size=None</em>, <em>learning_rate=0.0001</em>, <em>dim=1000</em>, <em>specificityAtSensitivityThreshold=0.5</em>, <em>sensitivityAtSpecificityThreshold=0.5</em>, <em>kernel_initializer=&lt;sphinx.ext.autodoc.importer._MockObject object&gt;</em>, <em>bias_initializer=&lt;sphinx.ext.autodoc.importer._MockObject object&gt;</em>, <em>output_activation='softmax'</em>, <em>isMultilabel=True</em>, <em>verbose=True</em><span class="sig-paren">)</span><a class="headerlink" href="#sbr.compile.one_layer_multicategorical" title="Permalink to this definition">¶</a></dt>
<dd><p>Compile a single layer multicategorical model. Can use <cite>sbr.visualize.plot_loss_curve</cite> to see the metrics after fitting</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>input_size [None]: usually <cite>x_train.shape[1]</cite>; not required for compile, but for calling <cite>model.summary()</cite>
output_size [None]: number of classes in the one-hot-encoded target vector; usually <cite>y_train.shape[1]</cite>
learning_rate [0.0001]: Plan for this to be reduced during <cite>EarlyStopping</cite> checkpoints in the model training/fit
dim [1000]: Number of nodes to have in the hidden layer. Somthing half-way between input_size and output_size is a good choice, but if input_size is very big, the number may need to be smaller in order to reduce the number of trainable parameters and avoid over-fitting.
specificityAtSensitivityThreshold [0.50]: With this percentage of sensitivity (e.g., detecting at least this many true positives), find the specificity (e.g., how many identified will actually be correct). This is a bit trickier for multivariate problems, see: <a class="reference external" href="https://www.analyticsvidhya.com/blog/2021/06/confusion-matrix-for-multi-class-classification/">https://www.analyticsvidhya.com/blog/2021/06/confusion-matrix-for-multi-class-classification/</a>
sensitivityAtSpecificityThreshold [0.50]:
kernel_initializer [tf.keras.initializers.HeNormal()]: HeNormal initializer forces diversity of outcomes between trainings
bias_initializder  [ tf.zeros_initializer()]:
output_activation [‘softmax’]:
isMultilabel [True]: Should alwasy be True for multicategorical models
verbose [True)]: If True, print model summary. Set to False if input_size = None to avoid error</dd>
</dl>
<p>Returns:</p>
<dl class="docutils">
<dt>Example usage:</dt>
<dd><dl class="first last docutils">
<dt>model = compile.one_layer_multicategorical(input_size=x_train.shape[1],</dt>
<dd>output_size=y_train.shape[1],
output_activation=’softmax’,
learning_rate=0.0001,
isMultilabel=True,
dim=1000,
specificityAtSensitivityThreshold=0.50,
sensitivityAtSpecificityThreshold=0.50,
verbose=True)</dd>
</dl>
</dd>
</dl>
</dd></dl>

<span class="target" id="module-sbr.evaluate"></span><dl class="function">
<dt id="sbr.evaluate.compare_predictions">
<code class="descclassname">sbr.evaluate.</code><code class="descname">compare_predictions</code><span class="sig-paren">(</span><em>model</em>, <em>x_test</em>, <em>y_test</em>, <em>class_names=None</em>, <em>verbose=True</em><span class="sig-paren">)</span><a class="headerlink" href="#sbr.evaluate.compare_predictions" title="Permalink to this definition">¶</a></dt>
<dd><p>Predicts y_test from x_test using model, then compares predictions with truth.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>model: the model to use <cite>model.predict</cite>
x_test: test features
y_test: targets
class_names: an ordered list of class name strings that map to the <cite>np.argmax(y_test,axis=1)</cite> indices in y_test. If none, class indices will be reported instead of strng names.
verbose: if verbose, pairs are printed out (good if there aren’t a lot of mislabeled predictions)</dd>
<dt>Returns:</dt>
<dd>(y_pred, pairs) where
y_pred: the predicted outcomes from x_test
pairs: list pairs of (&lt;truth&gt;&lt;false-prediction&gt;) class names</dd>
<dt>Exampe usasge:</dt>
<dd>y_pred, pairs = compare_predictions(model=model, x_test=x_test, y_test=ytest, class_names=class_names, verbose = True)</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="sbr.evaluate.mislabeled_pair_counts">
<code class="descclassname">sbr.evaluate.</code><code class="descname">mislabeled_pair_counts</code><span class="sig-paren">(</span><em>model</em>, <em>X</em>, <em>y</em>, <em>class_names</em>, <em>sample_ids=None</em>, <em>batch_size=1500</em>, <em>verbose=False</em><span class="sig-paren">)</span><a class="headerlink" href="#sbr.evaluate.mislabeled_pair_counts" title="Permalink to this definition">¶</a></dt>
<dd><p>For multicategorical models: creates a table of observed,
predicted class names for the mispredicted observations. This
tends to use a lot of memory on multiple runs in a jupyter
notebook, with tensorflow 2.6. May need to restart the kernel on
second run. If resources continue to be a problem after restarting
the kernel, reduce the batch_size.</p>
<p>Assumes y_pred, y_obs are one-hot encoded and class_names matches the index predictions returned from np.argmax(y_pred)</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>model: used for model.predict
X: feature values
y: one-hot encoded true labels
class_names: ordered list of class_names
sample_ids: pass in this Series object to get back a table of pairs with their sample_ids
batch_size: number of samples to process in each step (to keep from swamping memory)
verbose: helps with debugging; messages each step/batch</dd>
<dt>Returns:</dt>
<dd>(pairs_counts, pair_id_map) where
pairs_counts: Table with compound index ‘observed’,’predicted’ and one column, “counts”, with the count of all the
the samples in that observed/predicted mislabeled pair.
pair_id_map: None if sample_ids wasn’t passed in, otherwise returns a table with columns observed, predicted, sample_id</dd>
<dt>Example Usage:</dt>
<dd><dl class="first last docutils">
<dt>mislabeled_counts, mislabeled = mislabeled_pair_counts(model=model, X=X, y=y, class_names=class_names,</dt>
<dd>sample_ids = pd.Series(label_df[“sample_id”]),
batch_size=500)</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="sbr.evaluate.training_report">
<code class="descclassname">sbr.evaluate.</code><code class="descname">training_report</code><span class="sig-paren">(</span><em>model</em>, <em>x_test</em>, <em>y_test</em>, <em>sensitivityAtSpecificityThreshold=None</em>, <em>specificityAtSensitivityThreshold=None</em>, <em>verbose=True</em><span class="sig-paren">)</span><a class="headerlink" href="#sbr.evaluate.training_report" title="Permalink to this definition">¶</a></dt>
<dd><p>Calls <cite>model.evaluate(x_test,y_test)</cite> and, if verbose, reports on the performance, then returns a performance object.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>x_test: features
y_test: targets
verbose: if True, report to stdout
sensitivityAtSpecificityThreshold: If not None, and verbose, and this metric was captured in model.fit, report it to stdout
specificityAtSensitivityThreshold: see above</dd>
<dt>Returns:</dt>
<dd>performance object from the model.evaluate function; see <cite>Returns</cite> for <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/keras/Model#evaluate">https://www.tensorflow.org/api_docs/python/tf/keras/Model#evaluate</a></dd>
<dt>Example useage:</dt>
<dd><dl class="first last docutils">
<dt>performance = training_report(model, x_test, y_test,</dt>
<dd>sensitivityAtSpecificityThreshold=sensitivityAtSpecificityThreshold,
specificityAtSensitivityThreshold=specificityAtSensitivityThreshold,
verbose=True)</dd>
</dl>
</dd>
</dl>
</dd></dl>

<span class="target" id="module-sbr.fit"></span><dl class="function">
<dt id="sbr.fit.multicategorical_model">
<code class="descclassname">sbr.fit.</code><code class="descname">multicategorical_model</code><span class="sig-paren">(</span><em>model</em>, <em>model_folder</em>, <em>x_train</em>, <em>y_train</em>, <em>x_validation</em>, <em>y_validation</em>, <em>epochs=200</em>, <em>patience=4</em>, <em>lr_patience=2</em>, <em>lr_factor=0.1</em>, <em>batch_size=32</em>, <em>shuffle_value=100</em>, <em>initial_epoch=0</em>, <em>train_verbose=1</em>, <em>checkpoint_verbose=1</em><span class="sig-paren">)</span><a class="headerlink" href="#sbr.fit.multicategorical_model" title="Permalink to this definition">¶</a></dt>
<dd><p>Fits the given model with the given hyperparameters and multi-categorical data, after computing class weights and shuffling the data. Writes checkpoint and final model weights to model_folder. Look under variables/variables.* for weights. Reload with: <cite>model=load_model(‘f{model_path}’); model.load_weights(f”{model_folder}”)</cite></p>
<dl class="docutils">
<dt>Assumptions:</dt>
<dd><ul class="first last simple">
<li>Model has been compiled and saved to f”{model_path}.h5” (e.g., <cite>data/model/gtex/manual/gtex_model.h5</cite>)</li>
<li>Targets are one-hot encoded</li>
<li>Features have been normalized</li>
</ul>
</dd>
</dl>
<p>Tested with tensorflow v2.6.2, keras 2.6.0</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><p class="first">model: a compiled model
model_folder: writable folder to store the checkpoint and final model weights
x_train: training features, see sbr.split for help
y_train: training targets,  see above
x_validation: validation feature, see above
y_validation: validation feature, see above
epochs [200]: Number of epochs to train
patience [4]: Number of epochs with no improvement after which training will be stopped.
lr_patience [2]: Number of epochs with no improvement after which learning rate will be reduced.
lr_factor [0.1]: Factor by which the learning rate will be reduced. new_lr = lr * factor.
batch_size [32]: probably don’t change this, see: <a class="reference external" href="https://wandb.ai/ayush-thakur/dl-question-bank/reports/What-s-the-Optimal-Batch-Size-to-Train-a-Neural-Network---VmlldzoyMDkyNDU">https://wandb.ai/ayush-thakur/dl-question-bank/reports/What-s-the-Optimal-Batch-Size-to-Train-a-Neural-Network—VmlldzoyMDkyNDU</a>
shuffle_value [100]:
initial_epoch [0]: use this if you want to resume training at a particular epoch
train_verbose [0]: amount of information to print on each epoch. for 0: silent, 1: animited progress bar, 2: mentions epoch. For example:</p>
<blockquote>
<div><ul class="simple">
<li>0: &lt;silent&gt;</li>
<li>1: [==================]</li>
<li>2: Epoch 1/10</li>
</ul>
</div></blockquote>
<dl class="last docutils">
<dt>checkpoint_verbose [1]: amount of information to print on each epoch about the checkpoint. 0: silent.</dt>
<dd><ul class="first last simple">
<li>0: &lt;silent&gt;</li>
<li><dl class="first docutils">
<dt>1: Epoch 00015: val_loss improved from 0.06645 to 0.06611, saving model to data/model/gtex</dt>
<dd><a class="reference external" href="INFO:tensorflow:Assets">INFO:tensorflow:Assets</a> written to: data/model/gtex/assets</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</dd>
<dt>Returns:</dt>
<dd>history: A History object. Its History.history attribute is a record of training loss values and metrics values at successive epochs, as well as validation loss values and validation metrics values (if applicable). Use <cite>print(history.history.keys())</cite> to see all the hist and <cite>print(history.history[‘val_loss’])</cite> to print validation loss</dd>
</dl>
</dd></dl>

<span class="target" id="module-sbr.layers"></span><dl class="class">
<dt id="sbr.layers.BADBlock">
<em class="property">class </em><code class="descclassname">sbr.layers.</code><code class="descname">BADBlock</code><span class="sig-paren">(</span><em>units</em>, <em>activation='relu'</em>, <em>block_activation=None</em>, <em>dropout_rate=0.5</em>, <em>trainable=True</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#sbr.layers.BADBlock" title="Permalink to this definition">¶</a></dt>
<dd><p>Dense layer followed by Batch, Activation, Dropout. When popular
kwarg input_shape is passed, then will create a keras input layer
to insert before the current layer to avoid explicitly defining an
InputLayer.</p>
<p># Recreate this layer from its config:
layer = BADBlock(1000)
config = layer.get_config()
print(config)
new_layer = BADBlock.from_config(config)</p>
<p># use in a model:
import tensorflow as tf
from tensorflow.keras.layers import Dense
from tensorflow.keras.models import Sequential
from sbr.layers import BADBlock
model = Sequential()
model.add(BADBlock(1000, input_dim = 18963, activation=’relu’, dropout_rate=0.50, name=”BAD_1”))
model.add(Dense(26, activation=”softmax”))
model.summary()
model.compile(loss=’categorical_crossentropy’,optimizer=’adam’,metrics=[‘accuracy’,’mse’])</p>
</dd></dl>

<span class="target" id="module-sbr.model"></span><p>! [sbr.model.save] ERROR: model not saved. Exception (&lt;class ‘ValueError’&gt;) : Unknown layer: BADBlock. Please ensure this object is passed to the <cite>custom_objects</cite> argument. See <a class="reference external" href="https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object">https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object</a> for details.
! [sbr.model.save]    model_path=data/model/gtex/manual, file_name=gtex_model.h5, full_path=data/model/gtex/manual/gtex_model.h5</p>
<dl class="function">
<dt id="sbr.model.save_architecture">
<code class="descclassname">sbr.model.</code><code class="descname">save_architecture</code><span class="sig-paren">(</span><em>model</em>, <em>model_path=None</em>, <em>file_name='model.h5'</em>, <em>input_size=None</em>, <em>verbose=1</em><span class="sig-paren">)</span><a class="headerlink" href="#sbr.model.save_architecture" title="Permalink to this definition">¶</a></dt>
<dd><p>Saves the given model to the given path and name. It’s a good idea
to train and then run this in a notebook if possible so the train
model is resident in memory because this function can be tried
again in case it fails for some reason.</p>
<p>WARNING: THIS WILL OVER-WRITE ANY EXISTING MODEL.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>model: model object for calling <cite>model.save</cite>
model_path[None]: file path where model is to be written
file_name[“model.h5”]: name of the file, h5 format. Any exisiting file will be over-written.
input_size: if not None, attempts to check predictions on saved model are close to original model
verbose[1]: 0: debug, 1:print out model summary. This may throw an error if model wasn’t compiled with a known input size</dd>
<dt>Returns:</dt>
<dd>True on success, False otherwise. Check the return to try again if it fails while model is still resident in memory.</dd>
<dt>Example usage:</dt>
<dd>success = sbf.model.save(model, model_path=”data/model/manual”, file_name=”model.h5”, verbose=1)</dd>
</dl>
</dd></dl>

<span class="target" id="module-sbr.visualize"></span><dl class="function">
<dt id="sbr.visualize.plot_cm">
<code class="descclassname">sbr.visualize.</code><code class="descname">plot_cm</code><span class="sig-paren">(</span><em>y_test</em>, <em>y_pred</em>, <em>figsize=(10</em>, <em>10)</em>, <em>labelsize=20</em>, <em>textsize=15</em>, <em>classes=None</em><span class="sig-paren">)</span><a class="headerlink" href="#sbr.visualize.plot_cm" title="Permalink to this definition">¶</a></dt>
<dd><p>Makes a labelled confusion matrix comparing predictions and ground truth labels.</p>
<p>If classes is passed, confusion matrix will be labelled, if not, integer class values
will be used.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>y_test: Array of truth labels (must be same shape as y_pred).
y_pred: Array of predicted labels (must be same shape as y_true).
figsize: Size of output figure (default=(10, 10)).
label_size: Size of label text (default=20).
text_size: Size of output figure text (default=15).
classes: Array of class labels (e.g. string form). If <cite>None</cite>, integer labels are used.</dd>
<dt>Returns:</dt>
<dd>A labelled confusion matrix plot comparing y_test and y_pred.</dd>
<dt>Example usage:</dt>
<dd><dl class="first last docutils">
<dt>make_confusion_matrix(y_test=test_labels, # ground truth test labels</dt>
<dd>y_pred=y_preds, # predicted labels
classes=class_names, # array of class label names
figsize=(15, 15),
text_size=10)</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="sbr.visualize.plot_loss_curve">
<code class="descclassname">sbr.visualize.</code><code class="descname">plot_loss_curve</code><span class="sig-paren">(</span><em>history, figsize=(5, 5), metrics=['loss', 'accuracy', 'val_accuracy'], write_directory='data/images', file_name='nn-loss-curve.png', show_plot=True</em><span class="sig-paren">)</span><a class="headerlink" href="#sbr.visualize.plot_loss_curve" title="Permalink to this definition">¶</a></dt>
<dd><p>Plot a loss, accuracy curve. Assumes loss and accuracy were compiled into the model metrics.
If this is running in a notebook, the <cite>plt.show()</cite> command doesn’t matter and the plot will just who no matter what</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>history: history object returned from model.fit (or sbr.fit.multicategorical_model)
figsize [(5,5)]: tuple for the size of the figure
metrics []: traces to plot
write_directory [[‘loss’,’accuracy’]]: where to write out the figure (if None, nothing is saved)
file_name [“data/images”]: override filename of figure to be written
show [True]: if True, show to figure to display</dd>
<dt>Returns:</dt>
<dd>plots to display if show= True, saves image if write_directory not None</dd>
<dt>Example usage:</dt>
<dd><dl class="first last docutils">
<dt>plot_loss_curve(figsize=(5,5)</dt>
<dd>history, [‘loss’,’accuracy’,’val_accuracy’],
write_directory=”data/images”,
show=True)</dd>
</dl>
</dd>
</dl>
</dd></dl>

<span class="target" id="module-sbr.preprocessing.dataset"></span><dl class="function">
<dt id="sbr.preprocessing.dataset.multicategorical_split">
<code class="descclassname">sbr.preprocessing.dataset.</code><code class="descname">multicategorical_split</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>sample_count_threshold=100</em>, <em>test_fraction=0.1</em>, <em>validation_fraction=0.1</em>, <em>verbose=True</em>, <em>batch_size=32</em>, <em>seed=None</em>, <em>shuffle=True</em><span class="sig-paren">)</span><a class="headerlink" href="#sbr.preprocessing.dataset.multicategorical_split" title="Permalink to this definition">¶</a></dt>
<dd><p>Shuffles and splits X, y into test, train, validate; round dataset sizes to be a factor of batch_size.</p>
<p>Final dataset size is (sample_count_threshold * &lt;number of classes&gt;)</p>
<p>see also: sbr.gtex.dataset_setup</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>X: Features
y: multicategorical targets (more than one column)
sample_count_threshold: use about this many samples from each class
seed[None]: set this to make function deterministic/repeatable
shuffle[True]: probably don’t touch this. Shuffling the data really helps down-stream model training.</dd>
<dt>Returns:</dt>
<dd>(x_train, y_train, x_val, y_val, x_test, y_test)</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="sbr.preprocessing.dataset.trim_list_size_to_batch_size_factor">
<code class="descclassname">sbr.preprocessing.dataset.</code><code class="descname">trim_list_size_to_batch_size_factor</code><span class="sig-paren">(</span><em>batch_size=32</em>, <em>trim_list=None</em><span class="sig-paren">)</span><a class="headerlink" href="#sbr.preprocessing.dataset.trim_list_size_to_batch_size_factor" title="Permalink to this definition">¶</a></dt>
<dd><p>Trims the given list of multicategorical arrays down to a factor
of the given batch_size. This can avoid errors during training
when the dataset is very large, a small amount of data loss isn’t
a factor, and retaining a specfic batch_size (e.g., of 32) is
prefered .</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>trim_list: a list of arrays to be trimmed
batch_size[32]: probably leave this alone</dd>
<dt>Returns:</dt>
<dd>the same trim_list, but trimmed</dd>
<dt>Usage:</dt>
<dd>[x_train, y_train, x_val, y_val, x_test, y_test] = trim_list_size_to_batch_size_factor([x_train, y_train, x_val, y_val, x_test, y_test])</dd>
</dl>
</dd></dl>

<span class="target" id="module-sbr.preprocessing.gtex"></span><dl class="function">
<dt id="sbr.preprocessing.gtex.dataset_setup">
<code class="descclassname">sbr.preprocessing.gtex.</code><code class="descname">dataset_setup</code><span class="sig-paren">(</span><em>sample_count_threshold=100</em>, <em>expr_path='data/gtex/expr.ftr'</em>, <em>attr_path='dist/gtex/GTEx_Analysis_v8_Annotations_SampleAttributesDS.txt'</em>, <em>drop_classes_list=None</em>, <em>attr_class_name_column_name='SMTS'</em>, <em>attr_sample_id_column_name='SAMPID'</em>, <em>expr_sample_id_column_name='sample_id'</em>, <em>verbose=True</em><span class="sig-paren">)</span><a class="headerlink" href="#sbr.preprocessing.gtex.dataset_setup" title="Permalink to this definition">¶</a></dt>
<dd><p>Reads the expression and attribute feather files, normalizes the expression values, one-hot encodes the classes, and returns the features, targets and labels in coordinated order.</p>
<dl class="docutils">
<dt>The return from this function (X, y) can be split as such:</dt>
<dd><cite>x_train, x_test,y_train, y_test = sklearn.model_selection.train_test_split(X, np.array(y), test_size=1.-fraction, random_state=42, shuffle=True)</cite></dd>
<dt>Class names can be retrieved from the returned target aray (y) and ordered list of class names (class_names) as such:</dt>
<dd><a href="#id1"><span class="problematic" id="id2">``</span></a>class_names[np.argmax[y]]`</dd>
<dt>Args:</dt>
<dd>sample_count_threshold: drop any classes that are less than this threshold. If ‘None’, don’t drop any classes
expr_path:
attr_path:
drop_classes_list:
attr_class_name_column_name:
attr_sample_id_column_name:
expr_sample_id_column_name:
verbose:</dd>
<dt>Returns:</dt>
<dd>X: Normalized feature values
y: One-hot encoded target values
class_names: Ordered list of strings, one item per class. This will be handy for understanding the predictions
label_df:</dd>
<dt>Example usage;</dt>
<dd>X, y, class_names, label_df = dataset_setup(100)</dd>
</dl>
</dd></dl>

<div class="toctree-wrapper compound">
</div>
</div>
<div class="section" id="indices-and-tables">
<h1>Indices and tables<a class="headerlink" href="#indices-and-tables" title="Permalink to this headline">¶</a></h1>
<ul class="simple">
<li><a class="reference internal" href="genindex.html"><span class="std std-ref">Index</span></a></li>
<li><a class="reference internal" href="py-modindex.html"><span class="std std-ref">Module Index</span></a></li>
<li><a class="reference internal" href="search.html"><span class="std std-ref">Search Page</span></a></li>
</ul>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="#">sbr</a></h1>








<h3>Navigation</h3>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="#">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2022, K. Robasky.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.8.5</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.8</a>
      
      |
      <a href="_sources/index.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>